{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "exp.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xDU5XRqOtEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "input_path = \"/content/gdrive/My Drive/Colab Notebooks/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIKhhhGK9wGt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install surprise"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHMEQktejLHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from surprise import *\n",
        "import pandas as pd\n",
        "from surprise import accuracy\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1mkBGznjLHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_train_test_data(train_data_split):\n",
        "    train_df = pd.read_csv(\"/content/gdrive/My Drive/training.csv\", delimiter=\",\")  # read csv into df\n",
        "    reader = Reader(rating_scale=(1, 5))  # invoke reader instance of surprise library\n",
        "    print(\"Done with reading training data\")\n",
        "    if train_data_split == 1:\n",
        "        # train_df = train_df.sample(frac=0.7)\n",
        "        train_set_df, test_set_df = train_test_split(train_df, test_size=0.20)\n",
        "        train_dataset = Dataset.load_from_df(train_set_df, reader)\n",
        "        test_set_df.drop(['rating'], axis=1, inplace=True)\n",
        "        return train_dataset, test_set_df\n",
        "    else:\n",
        "        train_df.drop(['helpful' , 'reviewText', 'reviewTime', 'reviewerName', 'summary', 'unixReviewTime'] , axis=1, inplace=True)# drop timestamp coloumn\n",
        "        train_dataset = Dataset.load_from_df(train_df[['reviewerID', 'asin', 'overall']], reader)\n",
        "        train_set = train_dataset.build_full_trainset()\n",
        "    test_df = pd.read_csv(\"gdrive/My Drive/test_with_asin_reviewerID.csv\", delimiter=\",\")\n",
        "    print(\"Done with reading test data\")\n",
        "    return train_set, test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic2uN1EkjLHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_3(train_set, train_data_split):\n",
        "    print(\"Started training KNNBaseline..\")\n",
        "    '''\n",
        "    param_grid = {'k': [15, 20, 25, 30, 40, 50, 60]}\n",
        "    gs = GridSearchCV(KNNBasic, param_grid, measures=['rmse'], cv=5, n_jobs=5)\n",
        "    gs.fit(train_set)\n",
        "    print(\"Done with model 2 training\")\n",
        "    print(gs.best_params['rmse'])\n",
        "    knn_baseline = KNNBaseline(gs.best_params['rmse'])\n",
        "    '''\n",
        "    knn_baseline = KNNBaseline()\n",
        "    if train_data_split == 1:\n",
        "        knn_baseline.fit(train_set.build_full_trainset())\n",
        "    else:\n",
        "        knn_baseline.fit(train_set)\n",
        "    print(\"Done with KNNBaseline training\")\n",
        "    return knn_baseline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8r8wyjUjLH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_2(train_set, train_data_split):\n",
        "    print(\"Started training SVD..\")\n",
        "    '''\n",
        "    param_grid = {'n_epochs': [10, 20, 30], 'lr_all': [0.002, 0.005],\n",
        "                  'reg_all': [0.4, 0.6]}\n",
        "    gs = GridSearchCV(SVD, param_grid, measures=['rmse'], cv=3)\n",
        "    gs.fit(train_set)\n",
        "    print(\"Done with model 2 training\")\n",
        "    print(gs.best_params['rmse'])\n",
        "    svd = SVD(gs.best_params['rmse'])\n",
        "    '''\n",
        "    svd = SVD(n_factors=4,\n",
        "            n_epochs=80,\n",
        "            biased=False,\n",
        "            init_mean=0.0,\n",
        "            init_std_dev=0.2,\n",
        "            lr_bu = 0.39,\n",
        "            lr_bi = 0.25,\n",
        "            lr_pu = 0.055,\n",
        "            lr_qi = 0.055,\n",
        "            reg_bu = 0.045,\n",
        "            reg_bi = 0.040,\n",
        "            reg_pu = 0.0002,\n",
        "            reg_qi = 0.0003,\n",
        "            #lr_all=0.0085,\n",
        "            #reg_all=0.55,\n",
        "            random_state=4,\n",
        "            verbose=False)\n",
        "    if train_data_split == 1:\n",
        "        svd.fit(train_set.build_full_trainset())\n",
        "    else:\n",
        "        svd.fit(train_set)\n",
        "    print(\"Done with SVD training\")\n",
        "    return svd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QIbu5OtjLH5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model_1(train_set, train_data_split):\n",
        "    print(\"Started training BaselineOnly..\") \n",
        "    '''\n",
        "    param_grid = {'bsl_options': {'method': ['als'],\n",
        "                                  'n_epochs': [40, 50, 60],\n",
        "                                  'reg_i': [2, 5, 8],  # lambda 2\n",
        "                                  'reg_u': [1, 2, 3],  # lambda 3\n",
        "                                  }\n",
        "                  }\n",
        "    gs = GridSearchCV(BaselineOnly, param_grid, measures=['rmse'], cv=3, return_train_measures=True, n_jobs=1)\n",
        "    gs.fit(train_set)\n",
        "    print(\"Done with model 1 training\")\n",
        "    print(gs.best_params['rmse'])\n",
        "    base_line_only = BaselineOnly(gs.best_params['rmse'])\n",
        "    '''\n",
        "    # this is baseline configuration for optimizing the error\n",
        "    bsl_options = {'method': 'als',  # another option is sgd\n",
        "                   'n_epochs': 60,  # number of iterations\n",
        "                   'reg_u': 2,  # user-regularisation parameter\n",
        "                   'reg_i': 8  # item-regularisation parameter\n",
        "                   }\n",
        "    bl = BaselineOnly(bsl_options=bsl_options)\n",
        "    if train_data_split == 1:\n",
        "        bl.fit(train_set.build_full_trainset())\n",
        "    else:\n",
        "        bl.fit(train_set)\n",
        "    print(\"Done with BaselineOnly training\")\n",
        "    return bl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtzYZsrVjLH9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict_rating(test_df, model_1, model_2, model_3, train_data_split):\n",
        "    if train_data_split == 1:\n",
        "        if model_1 is not None:\n",
        "            predictions_1 = model_1.test(test_df)\n",
        "            accuracy.rmse(predictions_1, verbose=True)\n",
        "        if model_2 is not None:\n",
        "            predictions_2 = model_2.test(test_df)\n",
        "            accuracy.rmse(predictions_2, verbose=True)\n",
        "        if model_3 is not None:\n",
        "            predictions_3 = model_3.test(test_df)\n",
        "            accuracy.rmse(predictions_3, verbose=True)\n",
        "    else:\n",
        "        output_predictions_file = open('gdrive/My Drive/amazon_rating.csv', 'w')\n",
        "        output_predictions_file.write(\"key\" + \",\" + \"overall\" + \"\\n\")\n",
        "        print(\"Predicting ratings..\")\n",
        "        for i in range(0, len(test_df)):\n",
        "            if i % 50000 == 0:\n",
        "                print(i)\n",
        "            rating_p1 = None\n",
        "            rating_p2 = None\n",
        "            rating_p3 = None\n",
        "            output = None\n",
        "            predicted_rating = 0.0\n",
        "            model_count = 0\n",
        "            if model_1 is not None:\n",
        "                rating_p1 = model_1.predict(uid=test_df.iloc[i]['reviewerID'], iid=test_df.iloc[i]['asin'])\n",
        "                output = str(rating_p1[0]) + \"-\" + str(rating_p1[1]) + \",\"\n",
        "                predicted_rating = predicted_rating + float(rating_p1[3])\n",
        "                model_count = model_count + 1\n",
        "            if model_2 is not None:\n",
        "                rating_p2 = model_2.predict(uid=test_df.iloc[i]['reviewerID'], iid=test_df.iloc[i]['asin'])\n",
        "                output = str(rating_p2[0]) + \"-\" + str(rating_p2[1]) + \",\"\n",
        "                predicted_rating = predicted_rating + float(rating_p2[3])\n",
        "                model_count = model_count + 1\n",
        "            if model_3 is not None:\n",
        "                rating_p3 = model_3.predict(uid=test_df.iloc[i]['reviewerID'], iid=test_df.iloc[i]['asin'])\n",
        "                output = str(rating_p3[0]) + \"-\" + str(rating_p3[1]) + \",\"\n",
        "                predicted_rating = predicted_rating + float(rating_p3[3])\n",
        "                model_count = model_count + 1\n",
        "            if model_count > 0:\n",
        "               # predicted_rating = str(round(float(float(predicted_rating) / float(model_count))));\n",
        "                output = output + str(predicted_rating)\n",
        "            #print(rating_p1, rating_p2, rating_p3)\n",
        "            #print(output)\n",
        "            output_predictions_file.write(output + \"\\n\")\n",
        "        output_predictions_file.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnpNf-62jLIA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def main():\n",
        "    train_data_split = 0\n",
        "    train_data, test_data = create_train_test_data(train_data_split)\n",
        "    #model_1 = train_model_1(train_data, train_data_split)\n",
        "    model_1 = None\n",
        "    model_2 = train_model_2(train_data, train_data_split)\n",
        "   # model_3 = train_model_3(train_data, train_data_split)\n",
        "    model_3 = None\n",
        "    predict_rating(test_data, model_1, model_2, model_3, train_data_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GorB3CTFjLIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}